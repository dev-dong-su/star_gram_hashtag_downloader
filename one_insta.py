import csv
import datetime
import random
import time
import json
from instagrapi import Client
from instagrapi.exceptions import ClientError
import os
import requests

row_count = 1

# vpn í…ŒìŠ¤íŠ¸
#  60

# username = "moret64614"
# password = "snstest1"

username = "serij83151"
password = "snstest1"


def login_user():
    cl = Client()
    # cl.set_proxy("http://135.181.82.250:8080")
    print('ğŸŒ³ ê³„ì • ë¦¬ìŠ¤íŠ¸ ë¡œë”©.')
    with open('user-agent.json', 'r') as file:
        user_agents = json.load(file)

    user_agent = random.choice(user_agents)
    try:
        session = cl.load_settings(f"./sessions/{username}.json")
        if session:
            print('ì„¸ì…˜ ì •ë³´ë¥¼ í™œìš©í•´ ë¡œê·¸ì¸ì„ ì‹œë„í•©ë‹ˆë‹¤.')
            try:
                cl.set_settings(session)
                cl.login(username, password)
                cl.dump_settings(f"./sessions/{username}.json")

                try:
                    cl.get_timeline_feed()
                except:
                    print("ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•´ ì„¸ì…˜ì„ ê°±ì‹ í•©ë‹ˆë‹¤.")

                    old_session = cl.get_settings()

                    cl.set_settings({})
                    cl.set_uuids(old_session["uuids"])

                    cl.login(username, password)
                    cl.dump_settings(f"./sessions/{username}.json")
            except Exception as e:
                print("ì„¸ì…˜ ì •ë³´ë¥¼ í™œìš©í•´ ë¡œê·¸ì¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.: %s" % e)
    except:
        print(f'ğŸ¥” {username} ë¡œê·¸ì¸ì„ ì‹œë„í•©ë‹ˆë‹¤.')
        cl.set_user_agent(user_agent)
        cl.login(username, password)
        cl.dump_settings(f"./sessions/{username}.json")
        print(f'ğŸ¥” {username} ë¡œê·¸ì¸ ì™„ë£Œ.')

    return cl


def search_posts_by_hashtag(client, hashtag, max_posts=50):
    global row_count
    print(f'ğŸï¸ "{hashtag}" í•´ì‹œíƒœê·¸ì—ì„œ {max_posts}ê°œì˜ ê°œì‹œë¬¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.')
    posts = client.hashtag_medias_recent(hashtag, amount=max_posts)
    print('âœ… ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!')
    row_count += 1
    print(row_count)
    return posts


# def random_user_agent():
#     return random.choice(user_agents)


def download_media(url, local_path):
    response = requests.get(url)
    with open(local_path, "wb") as f:
        f.write(response.content)


def pretreatment_data(posts, hashtag, shop):
    filtered_posts = []

    # í˜„ì¬ ì‹œê°„(UTC ê¸°ì¤€) ê°€ì ¸ì˜¤ê¸°
    current_date_utc = datetime.datetime.now(datetime.timezone.utc).date()

    print(f"'{hashtag}' í•´ì‹œíƒœê·¸ì˜ ìµœê·¼ ê²Œì‹œë¬¼ ëª©ë¡:")
    for post in posts:
        post_date = post.taken_at.date()
        days_diff = (current_date_utc - post_date).days
        if days_diff <= 1:  # ì˜¤ëŠ˜ ì´ì „ìœ¼ë¡œ ë¶€í„° 1ì¼ ì´ë‚´ì¸ì§€ í™•ì¸
            print(
                f"- ê²Œì‹œë¬¼ ID: {post.id}, ìº¡ì…˜: {post.caption_text}, ì—…ë¡œë“œ ë‚ ì§œ: {post_date}")
            caption_text_words = post.caption_text.split()
            # hashtagì™€ shop ë¬¸ìì—´ì´ ë¶„ë¦¬ëœ caption_text_wordsì— ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if all(s in caption_text_words for s in [f"#{hashtag}"]) and any(s in caption_text_words for s in [f"#@{shop}", f"@{shop}"]):
                filtered_posts.append(post)
        else:
            print(
                f"- ê²Œì‹œë¬¼ ID: {post.id}, ìº¡ì…˜: {post.caption_text}, ì—…ë¡œë“œ ë‚ ì§œ: {post_date} (1ì¼ ì´ë‚´ ê²Œì‹œë¬¼ ì•„ë‹˜)")

    return filtered_posts


def save_posts_to_csv(posts, hashtag, shop, file_name="posts.csv"):
    if not posts:
        return

    filtered_posts = pretreatment_data(hashtag=hashtag, shop=shop, posts=posts)

    if not filtered_posts:
        return

    print('ğŸ›µ ê²Œì‹œë¬¼ì„ csvì— ì €ì¥í•©ë‹ˆë‹¤....')
    image_directory = f'images/{hashtag}'
    video_directory = f'video/{hashtag}'

    if not os.path.exists(image_directory):
        os.makedirs(image_directory)

    if not os.path.exists(video_directory):
        os.makedirs(video_directory)

    with open(file_name, mode="a", newline='', encoding="utf-8") as csvfile:
        csv_writer = csv.writer(csvfile, delimiter=',',
                                quotechar='"', quoting=csv.QUOTE_MINIMAL)

        for post in filtered_posts:
            print(post)

            if post.media_type == 1:
                tmp_local_directory = os.path.join(
                    image_directory, post.user.username)

                if not os.path.exists(tmp_local_directory):
                    os.makedirs(tmp_local_directory)
                local_file_path = os.path.join(
                    tmp_local_directory, f"{post.pk}.jpg")
                media_urls = post.thumbnail_url
                download_media(media_urls, local_file_path)

            elif post.media_type == 2:
                tmp_video_directory = os.path.join(
                    video_directory, post.user.username)
                if not os.path.exists(tmp_video_directory):
                    os.makedirs(tmp_video_directory)

                media_urls = post.video_url
                download_media(media_urls, local_video_file_path)

            elif post.media_type == 8:
                tmp_local_directory = os.path.join(
                    image_directory, post.user.username)

                if not os.path.exists(tmp_local_directory):
                    os.makedirs(tmp_local_directory)

                media_urls = []

                for index in post.resources:
                    if index.media_type == 2:
                        tmp_video_directory = os.path.join(
                            video_directory, post.user.username)
                        if not os.path.exists(tmp_video_directory):
                            os.makedirs(tmp_video_directory)

                        local_video_file_path = os.path.join(
                            tmp_video_directory, f"{post.pk}.mp4")
                        download_media(index.video_url, local_video_file_path)
                        media_urls.append(local_video_file_path)
                        continue

                    local_file_path = os.path.join(
                        tmp_local_directory, f"{index.pk}.jpg")
                    download_media(index.thumbnail_url, local_file_path)
                    media_urls.append(local_file_path)

            else:
                media_urls = ''

            formatted_date = post.taken_at.strftime("%Y-%m-%d %H:%M")
            csv_writer.writerow([f'https://www.instagram.com/p/{post.code}', post.id,  post.user.username,
                                post.caption_text, formatted_date, hashtag, post.like_count, post.comment_count, local_file_path])
        print('âœ… ì €ì¥ ì™„ë£Œ!')


# ì‹¤ì œ ì‘ë‹µ ëª¨ë¸ í…ŒìŠ¤íŒ…ìš©
# class Media:
#     def __init__(self, pk: str, id: str, code: str, taken_at: datetime, caption_text: str):
#         self.pk = pk
#         self.id = id
#         self.code = code
#         self.taken_at = taken_at
#         self.caption_text = caption_text


if __name__ == "__main__":
    print('ğŸ¥” ë¡œê·¸ì¸ì„ ì‹œë„í•©ë‹ˆë‹¤.')
    client = login_user()
    print('âœ… ë¡œê·¸ì¸ ì„±ê³µ!')

    request_count = 0

    # posts = search_posts_by_hashtag(client, "3509a0b1")
    # posts = [Media(pk='3034098679218183034', id='3034098679218183034_57304107125', code='CobSKxkSBt6', taken_at=datetime.datetime(2023, 4, 20, 00, 19, 29, tzinfo=datetime.timezone.utc), caption_text='#ì¡°ê³µ #ì¡°ì•¤ê°• ğŸ˜»\në„ˆë¬´ë„ˆë¬´ ê·€ì—¬ì›Œ ... \n@choandkang_official #ì¡°ê³µ #ì˜¤í‚¤ë¡œìŠ¤í‹±í™”ì´íŠ¸ #6a699\n@erounmart_kr #ì¡°ê³µ #í•œë°©ë³´ì–‘ì‚¼ê³„íƒ•ì „ #1e6656ff'),
    #          Media(pk='3034098679218183034', id='3034098679218183034_57304107125', code='CobSKxkSBt6', taken_at=datetime.datetime(2023, 4, 20, 00, 19, 29, tzinfo=datetime.timezone.utc), caption_text='#ì¡°ê³µ #ì¡°ì•¤ê°• ğŸ˜»\në„ˆë¬´ë„ˆë¬´ ê·€ì—¬ì›Œ ... \n@choandkang_official #ì¡°ê³µ #ì˜¤í‚¤ë¡œìŠ¤í‹±í™”ì´íŠ¸ #6a699\n@erounmart_kr #ì¡°ê³µ #í•œë°©ë³´ì–‘ì‚¼ê³„íƒ•ì „ #1e6656ff'),
    #          Media(pk='3034098679218183034', id='3034098679218183034_57304107125', code='CobSKxkSBt6', taken_at=datetime.datetime(2023, 4, 23, 00, 19, 29, tzinfo=datetime.timezone.utc), caption_text='#ì¡°ê³µ #ì¡°ì•¤ê°• ğŸ˜»\në„ˆë¬´ë„ˆë¬´ ê·€ì—¬ì›Œ ... \n@choandkang_official #ì¡°ê³µ \n@liferecipe.official #ì¡°ê³µ #í•œë°©ë³´ì–‘ì‚¼ê³„íƒ•ì „ #1e6656ff'),
    #          Media(pk='3034098679218183034', id='3034098679218183034_57304107125', code='CobSKxkSBt6', taken_at=datetime.datetime(2023, 4, 21, 00, 19, 29, tzinfo=datetime.timezone.utc), caption_text='#ì¡°ê³µ #ì¡°ì•¤ê°• ğŸ˜»\në„ˆë¬´ë„ˆë¬´ ê·€ì—¬ì›Œ ... \n@choandkang_official #ì¡°ê³µ \n@lowti_official #ì¡°ê³µ #í•œë°©ë³´ì–‘ì‚¼ê³„íƒ•ì „ #1e6656ff')]
    # save_posts_to_csv(posts=posts, hashtag="#6a699", shop='@erounmart_kr', file_name=f"snsreview.csv")

    posts = search_posts_by_hashtag(client, "5265830a")
    save_posts_to_csv(posts=posts, hashtag="5265830a",
                      shop='romistory_com', file_name=f"snsreview.csv")

    # with open("./hashtag_shop.csv", "r", encoding='utf-8') as csvfile:
    #     csv_reader = csv.reader(csvfile)
    #     start_line = 11
    #     row_count = start_line

    #     for line_number, row in enumerate(csv_reader, start=1):
    #         if line_number <= start_line:
    #             continue

    #         hashtag = row[0]
    #         shop = row[1]
    #         print(f'ğŸ” í•´ì‹œíƒœê·¸ ì²˜ë¦¬ ì‹œì‘: {hashtag}')
    #         try:
    #             if request_count == 30:
    #                 sleep_duration = random.randint(180, 300)
    #                 print(f'â²ï¸ {sleep_duration}ì´ˆ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.')

    #             posts = search_posts_by_hashtag(client, hashtag)
    #             save_posts_to_csv(posts=posts, shop=shop, hashtag=hashtag, file_name=f"snsreview.csv")

    #             request_count += 1
    #             sleep_duration = random.randint(1, 300)
    #             print(f'â²ï¸ {sleep_duration}ì´ˆ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.')
    #             time.sleep(sleep_duration)
    #         except Exception as e:
    #             if request_count == 30:
    #                 sleep_duration = random.randint(180, 300)
    #                 print(f'â²ï¸ {sleep_duration}ì´ˆ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.')

    #             print('ğŸ¥” ì„¸ì…˜ ë§Œë£Œ 30ì´ˆ ëŒ€ê¸° í›„ ë¡œê·¸ì¸ì„ ì‹œë„í•©ë‹ˆë‹¤.')
    #             client.logout()

    #             time.sleep(30)

    #             client = login_user()

    #             posts = search_posts_by_hashtag(client, hashtag)
    #             save_posts_to_csv(posts=posts, shop=shop, hashtag=hashtag, file_name=f"snsreview.csv")

    #             request_count += 1
    #             sleep_duration = random.randint(1, 120)
    #             print(f'â²ï¸ {sleep_duration}ì´ˆ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.')
    #             time.sleep(sleep_duration)
