import csv
import random
import json
import time
from instagrapi import Client
import os
import logging
import threading
import requests

# row_count = 509
row_count = 1000
hashtag_file = 1
row_count_lock = threading.Lock()

logger = logging.getLogger()


def login_user(account_index):
    cl = Client()

    user_agent = random_user_agent()
    random_device = generate_random_device()
    username = data['account'][account_index]['id']
    password = data['account'][account_index]['password']

    try:
        session = cl.load_settings(f"./sessions/{username}.json")
        if session:
            print('ì„¸ì…˜ ì •ë³´ë¥¼ í™œìš©í•´ ë¡œê·¸ì¸ì„ ì‹œë„í•©ë‹ˆë‹¤.')
            try:
                cl.set_settings(session)
                cl.login(username, password)
                cl.dump_settings(f"./sessions/{username}.json")

                try:
                    cl.get_timeline_feed()
                except:
                    print("ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•´ ì„¸ì…˜ì„ ê°±ì‹ í•©ë‹ˆë‹¤.")

                    old_session = cl.get_settings()

                    cl.set_settings({})
                    cl.set_uuids(old_session["uuids"])

                    cl.login(username, password)
                    cl.dump_settings(f"./sessions/{username}.json")
            except Exception as e:
                print("ì„¸ì…˜ ì •ë³´ë¥¼ í™œìš©í•´ ë¡œê·¸ì¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.: %s" % e)
    except:
        print(f'ğŸ¥” {username} ë¡œê·¸ì¸ì„ ì‹œë„í•©ë‹ˆë‹¤.')
        cl.set_user_agent(user_agent)
        cl.set_device(random_device)
        print(cl.settings)
        cl.login(username, password)
        cl.dump_settings(f"./sessions/{username}.json")
        print(f'ğŸ¥” {username} ë¡œê·¸ì¸ ì™„ë£Œ.')

    update_account_status(account_index, "running")
    return cl


def generate_random_device():
    return random.choice(device)


def random_user_agent():
    return random.choice(user_agents)


def search_posts_by_hashtag(client, hashtag, account_index, max_posts=1):
    global row_count
    row_count += 1
    print(row_count)

    print(f'ğŸï¸ {account_index}ë²ˆ ìŠ¤ë ˆë“œ:  "{hashtag}" í•´ì‹œíƒœê·¸ì—ì„œ {max_posts}ê°œì˜ ê°œì‹œë¬¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.')
    posts = client.hashtag_medias_recent(hashtag, amount=max_posts)
    print('âœ… ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!')
    return posts


def download_media(url, local_path):
    response = requests.get(url)
    with open(local_path, "wb") as f:
        f.write(response.content)


def save_posts_to_csv(posts, hashtag, file_name="posts.csv"):
    if not posts:
        return

    print('ğŸ›µ ê²Œì‹œë¬¼ì„ csvì— ì €ì¥í•©ë‹ˆë‹¤....')
    image_directory = f'images/{hashtag}'
    video_directory = f'video/{hashtag}'

    if not os.path.exists(image_directory):
        os.makedirs(image_directory)

    with open(file_name, mode="a", newline='', encoding="utf-8") as csvfile:
        csv_writer = csv.writer(csvfile, delimiter=',',
                                quotechar='"', quoting=csv.QUOTE_MINIMAL)

        csv_writer.writerow(['permalink', 'media_id', 'username', 'caption_text',
                            'hashtag', 'like_count', 'comment_count', 'local_file_path'])

        for post in posts:
            # ë‹¨ì¼ ì‚¬ì§„ ê²Œì‹œë¬¼ ì²˜ë¦¬
            if post.media_type == 1:
                tmp_local_directory = os.path.join(
                    image_directory, post.user.username)

                if not os.path.exists(tmp_local_directory):
                    os.makedirs(tmp_local_directory)
                local_file_path = os.path.join(
                    tmp_local_directory, f"{post.pk}.jpg")
                media_urls = post.thumbnail_url
                download_media(media_urls, local_file_path)

            # ì˜ìƒ ê²Œì‹œë¬¼ ì²˜ë¦¬
            elif post.media_type == 2:
                tmp_video_directory = os.path.join(
                    video_directory, post.user.username)
                if not os.path.exists(tmp_video_directory):
                    os.makedirs(tmp_video_directory)

                media_urls = post.video_url
                download_media(media_urls, local_video_file_path)

            # ì‚¬ì§„, ì˜ìƒ ë¬¶ìŒ ê²Œì‹œë¬¼ ì²˜ë¦¬
            elif post.media_type == 8:
                tmp_local_directory = os.path.join(
                    image_directory, post.user.username)

                if not os.path.exists(tmp_local_directory):
                    os.makedirs(tmp_local_directory)

                media_urls = []

                for index in post.resources:
                    if index.media_type == 2:
                        tmp_video_directory = os.path.join(
                            video_directory, post.user.username)
                        if not os.path.exists(tmp_video_directory):
                            os.makedirs(tmp_video_directory)

                        local_video_file_path = os.path.join(
                            tmp_video_directory, f"{post.pk}.mp4")
                        download_media(index.video_url, local_video_file_path)
                        media_urls.append(local_video_file_path)
                        continue

                    local_file_path = os.path.join(
                        tmp_local_directory, f"{post.pk}.jpg")
                    download_media(index.thumbnail_url, local_file_path)
                    media_urls.append(local_file_path)

            else:
                media_urls = ''

            csv_writer.writerow([f'https://www.instagram.com/p/{post.code}', post.id,  post.user.username,
                                post.caption_text, hashtag, post.like_count, post.comment_count, local_file_path])
        print('âœ… ì €ì¥ ì™„ë£Œ!')


def process_hashtags(client, account_index, account_list):
    global row_count
    global hashtag_file

    request_count = 0
    thread_delay_count = 0
    max_request_count = random.randint(30, 40)

    while True:
        with row_count_lock:
            hashtag = hashtags[row_count - 1]
            row_count += 1

        try:
            if thread_delay_count == random.randint(10, 20):
                time.sleep(120)
                print(
                    f'â²ï¸ {account_index}ë²ˆ {sleep_duration}ìš”ì²­ ì‚¬ì´ì— 120ì´ˆ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.')

            posts = search_posts_by_hashtag(client, hashtag, account_index)
            save_posts_to_csv(posts, hashtag, f"snsreview.csv")

            sleep_duration = random.randint(10, 20)
            print(f'â²ï¸ {account_index} ë²ˆ {sleep_duration}ì´ˆ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.')
            time.sleep(sleep_duration)

            thread_delay_count += 1
            request_count += 1  # ìš”ì²­ íšŸìˆ˜ ì¦ê°€

            # ìš”ì²­ íšŸìˆ˜ê°€ 40ì— ë„ë‹¬í•˜ë©´, ê³„ì •ì„ êµì²´
            if request_count >= max_request_count:
                # í˜„ì¬ ê³„ì • ìƒíƒœë¥¼ 'ready'ë¡œ ë³€ê²½
                update_account_status(account_index, "ready")
                ready_accounts = [i for i, account in enumerate(
                    account_list) if account["status"] == "ready"]  # 'ready'ì¸ ê³„ì • ëª©ë¡ì„ ê°€ì ¸ì˜´

                if not ready_accounts:
                    print("ëª¨ë“  ê³„ì •ì´ ì‚¬ìš© ì¤‘ì´ê±°ë‚˜ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
                    time.sleep(180)
                    ready_accounts = [i for i, account in enumerate(
                        account_list) if account["status"] == "ready"]

                account_index = random.choice(
                    ready_accounts)  # 'ready'ì¸ ê³„ì • ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ
                client = login_user(account_index)  # ìƒˆë¡œìš´ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.
                request_count = 0  # ìš”ì²­ íšŸìˆ˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
                max_request_count = random.randint(30, 40)

        except Exception as e:
            print(f'ğŸ¥” {account_index} ë²ˆ ì¸ìŠ¤íƒ€ì—ê²Œ ë“¤ì¼°ìŠµë‹ˆë‹¤! 30ì´ˆ ëŒ€ê¸° í›„ ë¡œê·¸ì¸ì„ ì‹œë„í•©ë‹ˆë‹¤.')
            time.sleep(30)

            update_account_status(account_index, "ban")

            ready_accounts = [i for i, account in enumerate(
                account_list) if account["status"] == "ready"]  # 'ready'ì¸ ê³„ì • ëª©ë¡ì„ ê°€ì ¸ì˜´

            if not ready_accounts:
                print("ëª¨ë“  ê³„ì •ì´ ì‚¬ìš© ì¤‘ì´ê±°ë‚˜ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
                time.sleep(180)
                ready_accounts = [i for i, account in enumerate(
                    account_list) if account["status"] == "ready"]

            account_index = random.choice(
                ready_accounts)  # 'ready'ì¸ ê³„ì • ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ
            client = login_user(account_index)  # ìƒˆë¡œìš´ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.
            request_count = 0

            posts = search_posts_by_hashtag(client, hashtag, account_index,)
            save_posts_to_csv(posts, hashtag, f"snsreview.csv")

            sleep_duration = random.randint(10, 20)
            print(f'â²ï¸ {account_index} ë²ˆ  {sleep_duration}ì´ˆ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.')
            time.sleep(sleep_duration)


def update_account_status(account_index, new_status):
    data['account'][account_index]['status'] = new_status
    with open('account.json', 'w') as file:
        json.dump(data, file)


if __name__ == "__main__":
    print('ğŸŒ³ í•„ìš”í•œ ë³€ìˆ˜ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.')

    print('ğŸŒ³ ê³„ì • ë¦¬ìŠ¤íŠ¸ ë¡œë”©.')
    with open('account.json', 'r') as file:
        data = json.load(file)
    print(f'{len(data)}ê°œ ë¡œë”© ì™„ë£Œ.')

    print('ğŸŒ³ User Agent ë¦¬ìŠ¤íŠ¸ ë¡œë”©.')
    with open('user-agent.json', 'r') as file:
        user_agents = json.load(file)

    print('ğŸŒ³ Device ë¦¬ìŠ¤íŠ¸ ë¡œë”©.')
    with open('device.json', 'r') as file:
        device = json.load(file)

    print(f'{len(device)}ê°œ ë¡œë”© ì™„ë£Œ.')

    # í•´ì‹œíƒœê·¸ ì½ì–´ì˜¤ê¸°
    with open(f"./hashtags/hashtagá„†á…©á†¨á„…á…©á†¨_{hashtag_file}.csv", "r", encoding='utf-8') as csvfile:
        csv_reader = csv.reader(csvfile)
        hashtags = [row[0] for row in csv_reader]
        num_lines = len(hashtags)

    available_accounts = [
        account for account in data['account'] if account["status"] != "ban"]

    num_accounts = len(available_accounts)

    clients = [login_user(i) for i in range(1) if i < num_accounts]

    threads = [threading.Thread(target=process_hashtags, args=(
        client, i, available_accounts)) for i, client in enumerate(clients)]

    for t in threads:
        t.start()

    for t in threads:
        t.join()
